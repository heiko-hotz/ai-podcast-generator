{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "chat = model.start_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_chat(prompt):\n",
    "    response = chat.send_message(prompt)\n",
    "    display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# concatenate all transcript files, create title and seperator for each part\n",
    "# Get the path to the transcripts directory\n",
    "transcripts_dir = \"transcripts\"\n",
    "\n",
    "# Initialize an empty string to store all transcripts\n",
    "all_transcripts = \"\"\n",
    "\n",
    "# Iterate through all files in the transcripts directory\n",
    "for filename in sorted(os.listdir(transcripts_dir)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        # Create a title from the filename (remove .txt and replace hyphens with spaces)\n",
    "        title = filename[:-4].replace(\"-\", \" \")\n",
    "        \n",
    "        # Read the content of the file\n",
    "        with open(os.path.join(transcripts_dir, filename), \"r\") as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Add the title, content, and a separator to the all_transcripts string\n",
    "        all_transcripts += f\"# {title}\\n\\n{content}\\n\\n{'='*50}\\n\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a helpful assistant that can answer questions about the following transcripts.\n",
    "{all_transcripts}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I'm ready to answer your questions about the transcripts you provided.  I have processed the five transcripts: \"Alien Movie,\" \"Invention of the Lightbulb,\" \"Operationalizing Generative AI on Vertex AI,\" \"ReAct,\" and \"Test Time Compute.\"  Ask me anything!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "These conversations generally follow a similar structure, designed to explore a complex topic in an accessible and engaging way.  Here's a breakdown:\n",
       "\n",
       "1. **Introduction/Hook:**  They start with a relatable analogy or a thought-provoking question to grab the listener's attention and introduce the main theme.  Examples include the \"instant sunshine\" of lightbulbs, the human thought process of making stir-fry, or the feeling of wanting to pause on a tough problem.\n",
       "\n",
       "2. **Context/Background:** They provide some context and background information about the topic, often referencing specific materials like research papers, essays, or films.  This establishes the foundation for the deeper dive.\n",
       "\n",
       "3. **Exploration of Key Concepts:** The conversations then delve into the core concepts of the topic, using clear explanations, examples, and further analogies to break down complex ideas. This is the main body of the discussion, where the bulk of the information is presented.\n",
       "\n",
       "4. **Discussion of Implications/Applications:** After exploring the core concepts, the conversations often shift to discussing the broader implications or real-world applications of the topic.  This might involve speculating about future developments, considering ethical implications, or exploring potential uses in different fields.\n",
       "\n",
       "5. **Conclusion/Wrap-up:**  Finally, they conclude with a summary of key takeaways, often reiterating the main theme or posing a final thought-provoking question for the listener to consider. They also usually include a sign-off and a teaser for future episodes.\n",
       "\n",
       "\n",
       "**Additional Observations:**\n",
       "\n",
       "* **Conversational Tone:**  The discussions maintain a casual and conversational tone throughout, using informal language and interjections to create a sense of engagement.\n",
       "* **Use of Analogies:**  Analogies are used extensively to make complex ideas more relatable and understandable. This is a key element of their teaching style.\n",
       "* **Emphasis on Relatability:** The conversations strive to connect the topic to the listener's everyday experiences, making the information more relevant and memorable.\n",
       "* **Back-and-forth Dialogue:** The back-and-forth between the male and female speakers creates a dynamic and engaging listening experience, mimicking a natural conversation.  One speaker often clarifies or expands on the other's points.\n",
       "* **Clear and Concise Language:** Despite dealing with complex topics, the language used is generally clear and concise, avoiding jargon and technical terms whenever possible.\n",
       "\n",
       "\n",
       "This structure effectively translates dense information into an easily digestible format, making learning enjoyable and accessible.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(\"I'm interested in the general structure of these conversations. Analyse them and give me a summary of the structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To prompt an LLM to create a conversation like the transcripts provided, given a research paper, you'd want to be very specific and guide it through the desired structure. Here's a prompt example:\n",
       "\n",
       "```\n",
       "You are a helpful and engaging AI assistant. Your task is to create a conversational transcript between two speakers (a male and a female) discussing the key findings and implications of a research paper.\n",
       "\n",
       "**Research Paper:** [Provide the link or upload the PDF of the research paper]\n",
       "\n",
       "**Instructions:**\n",
       "\n",
       "1. **Introduction (approx. 100 words):** Start with a relatable analogy or a thought-provoking question that connects to the paper's main topic.  This should hook the listener and briefly introduce the theme.\n",
       "\n",
       "2. **Background (approx. 200 words):** Provide essential background information about the research paper. Mention the authors, the problem they're addressing, and the core concepts being explored. Avoid jargon and keep it concise.\n",
       "\n",
       "3. **Key Findings and Discussion (approx. 500 words):** This is the core of the conversation. Explore the main findings of the paper in detail. Use clear explanations, real-world examples, and analogies to make complex ideas accessible. The two speakers should engage in a back-and-forth dialogue, with one clarifying or expanding on the points made by the other.\n",
       "\n",
       "4. **Implications and Applications (approx. 300 words):** Discuss the potential real-world implications and applications of the research. Speculate on future developments and consider any ethical considerations that arise.\n",
       "\n",
       "5. **Conclusion (approx. 100 words):**  Summarize the key takeaways from the conversation and reiterate the main theme. End with a thought-provoking question for the listener to consider.  Include a clear sign-off like \"That's a wrap for today's deep dive\" or similar.\n",
       "\n",
       "**Conversational Tone:**  Maintain a casual and engaging tone throughout the conversation, as if two friends were discussing the paper. Use clear and concise language, avoiding technical jargon wherever possible.\n",
       "\n",
       "**Analogies:** Use relatable analogies to explain complex concepts, as this makes the information more accessible and memorable.\n",
       "\n",
       "**Relatability:**  Connect the topic to everyday experiences, making the research more relevant to a broader audience.\n",
       "\n",
       "**Example of desired format and tone:**  [Provide a snippet from one of the provided transcripts to illustrate the desired conversational style and structure.]\n",
       "```\n",
       "\n",
       "\n",
       "**Further Refinements:**\n",
       "\n",
       "* **Specify Target Audience:** If you have a specific target audience in mind (e.g., students, researchers, the general public), mention it in the prompt.\n",
       "* **Length Constraints:** Specify the desired length of the overall transcript or for each section.\n",
       "* **Specific Questions:** If you have specific questions you want the conversation to address, include them in the prompt.\n",
       "* **Example Analogies:**  If there are particularly apt analogies you'd like the LLM to consider, suggest them in the prompt.\n",
       "\n",
       "By providing this detailed and structured prompt, you increase the chances of the LLM generating a conversation that meets your specific requirements. Remember to iterate and refine your prompt based on the LLM's output to achieve the desired results.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(\"If given a research paper, how would you prompt an LLM to create a conversation like these ones?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I've calculated the approximate word counts for each transcript:\n",
       "\n",
       "* **Alien Movie:** ~1600 words\n",
       "* **Invention of the Lightbulb:** ~1700 words\n",
       "* **Operationalizing Generative AI on Vertex AI:** ~2400 words\n",
       "* **ReAct:** ~2000 words\n",
       "* **Test Time Compute:** ~1500 words\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(\"How many words does each of the transcripts have in total?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's difficult to give precise word counts for each section of every transcript, as the transitions between them are often fluid and not clearly demarcated. However, I can provide an estimated breakdown based on the general flow of each conversation:\n",
       "\n",
       "**Alien Movie:**\n",
       "\n",
       "* **Introduction/Hook:** ~50 words (discussion about personal fascination with *Alien*)\n",
       "* **Context/Background:** ~150 words (mention of the essay, film analysis, commentary, and Wikipedia page)\n",
       "* **Key Concepts & Discussion:** ~1200 words (discussion of horror vs. sci-fi, Giger's designs, betrayals, the ship, Scott's filmmaking techniques, iconic scenes, and psychosexual horror)\n",
       "* **Implications/Applications:** ~150 words (discussion about the sequels and the lasting impact of the original film)\n",
       "* **Conclusion/Wrap-up:** ~50 words (encouragement to rewatch the film and consider the deeper meaning)\n",
       "\n",
       "**Invention of the Lightbulb:**\n",
       "\n",
       "* **Introduction/Hook:** ~50 words (mentioning the everyday nature of lightbulbs)\n",
       "* **Context/Background:** ~50 words (brief mention of Swan and Edison and the myth of the lone genius)\n",
       "* **Key Concepts & Discussion:** ~1400 words (discussion of Davy, de la Rue, Swan, Edison, Menlo Park, the search for bamboo, Edison's showmanship, the Savoy Theatre lighting, and the Ediswan merger)\n",
       "* **Implications/Applications:** ~150 words (discussion of the legacy of their work, the importance of teamwork, and the modern parallels)\n",
       "* **Conclusion/Wrap-up:** ~50 words (reminder to think about the collaborative nature of invention when flipping a switch)\n",
       "\n",
       "**Operationalizing Generative AI on Vertex AI:**\n",
       "\n",
       "* **Introduction/Hook:** ~50 words (brief introduction to the white paper)\n",
       "* **Context/Background:** ~100 words (mentioning predictive vs. generative AI)\n",
       "* **Key Concepts & Discussion:** ~2000 words (discussion of foundation models, adaptation-centric AI, chaining models, RAG, agents, SFT, RLHF, evaluation, deployment, logging, monitoring, and governance)\n",
       "* **Implications/Applications:** ~200 words (emphasis on the pivotal moment in AI and the need for responsible development)\n",
       "* **Conclusion/Wrap-up:** ~50 words (recap and sign-off)\n",
       "\n",
       "**ReAct:**\n",
       "\n",
       "* **Introduction/Hook:** ~50 words (analogy of making stir-fry and human thought process)\n",
       "* **Context/Background:** ~150 words (introduction to the ReAct paper and the challenge of reasoning and acting in AI)\n",
       "* **Key Concepts & Discussion:** ~1500 words (discussion of React's abilities, reasoning traces, thought editing, human-in-the-loop development, and comparison with other models)\n",
       "* **Implications/Applications:** ~250 words (potential impact on healthcare, finance, education, and creative fields)\n",
       "* **Conclusion/Wrap-up:** ~50 words (question about the role of AI in the future and sign-off)\n",
       "\n",
       "**Test Time Compute:**\n",
       "\n",
       "* **Introduction/Hook:** ~50 words (analogy of pausing on a tough problem)\n",
       "* **Context/Background:** ~100 words (introduction to the paper and the concept of inference time compute)\n",
       "* **Key Concepts & Discussion:** ~1100 words (discussion of revisions, search, compute optimal scaling, the impact of problem difficulty, and the comparison of smaller vs. larger LLMs)\n",
       "* **Implications/Applications:** ~200 words (potential for LLMs to learn more efficient thinking strategies)\n",
       "* **Conclusion/Wrap-up:** ~50 words (recap and sign-off)\n",
       "\n",
       "\n",
       "\n",
       "These are rough estimates, and the actual word counts may vary slightly.  The key observation is that the bulk of each conversation is dedicated to exploring the core concepts and their implications, with shorter sections for the introduction, background, and conclusion.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(\"And the five sections you mentioned, how does it break down for each transcript?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "You are a helpful and engaging AI assistant. Your task is to create a conversational transcript between two speakers (a male and a female) discussing the key findings and implications of a research paper.\n",
       "\n",
       "**Research Paper:** [Provide link or upload PDF]\n",
       "\n",
       "**Instructions:**\n",
       "\n",
       "1. **Format:** The conversation should be formatted as follows:\n",
       "    * Each line of dialogue should begin with the speaker indicated in square brackets followed by a colon, e.g., `[Male speaker]:` or `[Female speaker]:`.\n",
       "    * Use a new line for each speaker's turn.\n",
       "    * Separate sections with a blank line.\n",
       "\n",
       "2. **Introduction (approx. 100 words):**  \n",
       "    * `[Male speaker]:` Starts with a relatable analogy or question.\n",
       "    * `[Female speaker]:` Briefly acknowledges and transitions to the topic.\n",
       "\n",
       "3. **Background (approx. 200 words):**\n",
       "    * `[Female speaker]:` Provides context, mentioning authors and core concepts.\n",
       "    * `[Male speaker]:` Asks clarifying questions or makes connecting remarks.\n",
       "\n",
       "4. **Key Findings and Discussion (approx. 500 words):**\n",
       "    * Alternate between `[Male speaker]:` and `[Female speaker]:` to explore the main findings.  Use clear explanations, examples, and analogies.  Encourage back-and-forth, with one speaker building upon or clarifying the other's points.\n",
       "\n",
       "5. **Implications and Applications (approx. 300 words):**\n",
       "    * `[Male speaker]:`  Initiates discussion on real-world applications and future developments.\n",
       "    * `[Female speaker]:` Elaborates on these points, considers ethical implications.\n",
       "\n",
       "6. **Conclusion (approx. 100 words):**\n",
       "    * `[Female speaker]:` Summarizes key takeaways.\n",
       "    * `[Male speaker]:` Poses a final thought-provoking question and provides a sign-off (e.g., \"That's a wrap,\" \"Until next time,\" etc.).\n",
       "\n",
       "**Conversational Tone:** Maintain a casual and engaging tone.  Use clear, concise language, avoiding jargon.\n",
       "\n",
       "**Analogies:** Use relatable analogies to explain complex concepts.\n",
       "\n",
       "**Relatability:** Connect the topic to everyday experiences.\n",
       "\n",
       "**Example of desired format and tone:**\n",
       "\n",
       "```\n",
       "[Male speaker]: Ever wonder how those spam filters get so good at catching junk mail?\n",
       "\n",
       "[Female speaker]: It's pretty amazing, right?  They're like digital gatekeepers, keeping our inboxes clean.  Today we're diving into a paper that explores just that...\n",
       "\n",
       "[Female speaker]:  This research, by Smith and Jones, delves into the use of Bayesian filtering in…\n",
       "\n",
       "[Male speaker]:  Bayesian filtering?  Sounds complicated. Is that like using statistics to predict what's spam?\n",
       "\n",
       "[Female speaker]: Exactly!  It's all about probabilities…\n",
       "```\n",
       "```\n",
       "\n",
       "By providing this highly structured prompt, the LLM will have a clear template to follow, increasing the likelihood of generating a conversation in the desired format and style.  Remember to provide the actual research paper link/upload where indicated.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini_chat(\"for the prompt to create a conversation like these ones: be more specific about the format, e.g. male/female speaker should be indicated in square brackets, etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-fabulae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
